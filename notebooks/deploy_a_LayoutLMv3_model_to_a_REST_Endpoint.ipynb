{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üë©üèΩ‚Äçüíª Setup"
      ],
      "metadata": {
        "id": "Uu_xHT2yEJOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "8rlGxQJJtQ5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "uYSQQ2DHvSr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade modelbit"
      ],
      "metadata": {
        "id": "u6z95Ipt7x0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from datasets.features import ClassLabel\n",
        "from transformers import AutoProcessor, AutoModelForTokenClassification\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import requests\n",
        "import torch"
      ],
      "metadata": {
        "id": "STfYGiy_vXfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import modelbit\n",
        "mb = modelbit.login()"
      ],
      "metadata": {
        "id": "qajG25vLFxlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mb.switch_branch(\"development\")"
      ],
      "metadata": {
        "id": "7EBLUc7yGDkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìú Document Processing Helpers and Pre-Configuration\n"
      ],
      "metadata": {
        "id": "XfO_JAtuGIsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"nielsr/funsd-layoutlmv3\")\n",
        "\n",
        "example = dataset[\"test\"][1]\n",
        "image = example['image']\n",
        "words = example['tokens']\n",
        "boxes = example['bboxes']\n",
        "word_labels = example['ner_tags']\n",
        "\n",
        "features = dataset[\"train\"].features\n",
        "column_names = dataset[\"train\"].column_names\n",
        "image_column_name = \"image\"\n",
        "text_column_name = \"tokens\"\n",
        "boxes_column_name = \"bboxes\"\n",
        "label_column_name = \"ner_tags\"\n",
        "\n",
        "def unnormalize_box(bbox, width, height):\n",
        "     return [\n",
        "         width * (bbox[0] / 1000),\n",
        "         height * (bbox[1] / 1000),\n",
        "         width * (bbox[2] / 1000),\n",
        "         height * (bbox[3] / 1000),\n",
        "     ]\n",
        "\n",
        "def get_label_list(labels):\n",
        "    unique_labels = set()\n",
        "    for label in labels:\n",
        "        unique_labels = unique_labels | set(label)\n",
        "    label_list = list(unique_labels)\n",
        "    label_list.sort()\n",
        "    return label_list\n",
        "\n",
        "def iob_to_label(label):\n",
        "    label = label[2:]\n",
        "    if not label:\n",
        "      return 'other'\n",
        "    return label\n",
        "\n",
        "if isinstance(features[label_column_name].feature, ClassLabel):\n",
        "    label_list = features[label_column_name].feature.names\n",
        "    # No need to convert the labels since they are already ints.\n",
        "    id2label = {k: v for k,v in enumerate(label_list)}\n",
        "    label2id = {v: k for k,v in enumerate(label_list)}\n",
        "else:\n",
        "    label_list = get_label_list(dataset[\"train\"][label_column_name])\n",
        "    id2label = {k: v for k,v in enumerate(label_list)}\n",
        "    label2id = {v: k for k,v in enumerate(label_list)}\n",
        "\n",
        "num_labels = len(label_list)"
      ],
      "metadata": {
        "id": "n2gG1Tdt79Q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üí™üèæ Building the Model"
      ],
      "metadata": {
        "id": "8IRuIL8hGPCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=False)"
      ],
      "metadata": {
        "id": "xmnUl4UPEfBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(\"microsoft/layoutlmv3-base\", id2label=id2label, label2id=label2id)"
      ],
      "metadata": {
        "id": "nCTqD1bUtmp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üß† Inference"
      ],
      "metadata": {
        "id": "Vttg8RJaGT50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_document_text(image_url):\n",
        "  # Download image from image_url\n",
        "  image = Image.open(requests.get(image_url, stream=True).raw)\n",
        "\n",
        "  # Build image encoding\n",
        "  encoding = processor(image, words, word_labels=word_labels, boxes=boxes, return_tensors=\"pt\")\n",
        "\n",
        "  # Take one step\n",
        "  with torch.no_grad():\n",
        "    outputs = model(**encoding)\n",
        "  logits = outputs.logits\n",
        "\n",
        "  # Get model predictions\n",
        "  predictions = logits.argmax(-1).squeeze().tolist()\n",
        "\n",
        "  # Map predictions to image document\n",
        "  token_boxes = encoding.bbox.squeeze().tolist()\n",
        "  width, height = image.size\n",
        "  labels = encoding.labels.squeeze().tolist()\n",
        "  true_predictions = [model.config.id2label[pred] for pred, label in zip(predictions, labels) if label != - 100]\n",
        "  true_labels = [model.config.id2label[label] for prediction, label in zip(predictions, labels) if label != -100]\n",
        "  true_boxes = [unnormalize_box(box, width, height) for box, label in zip(token_boxes, labels) if label != -100]\n",
        "\n",
        "  # Draw predictions on image document\n",
        "  draw = ImageDraw.Draw(image)\n",
        "  font = ImageFont.load_default()\n",
        "  label2color = {'question':'blue', 'answer':'green', 'header':'orange', 'other':'violet'}\n",
        "\n",
        "  for prediction, box in zip(true_predictions, true_boxes):\n",
        "    predicted_label = iob_to_label(prediction).lower()\n",
        "    draw.rectangle(box, outline=label2color[predicted_label])\n",
        "    draw.text((box[0] + 10, box[1] - 10), text=predicted_label, fill=label2color[predicted_label], font=font)\n",
        "\n",
        "  if not mb.in_modelbit():\n",
        "    display(image)\n",
        "  mb.log_image(image)\n",
        "\n",
        "  # Return raw predictions for computational use\n",
        "  return predictions\n",
        "\n",
        "classify_document_text(\"https://doc.modelbit.com/img/memo.png\")"
      ],
      "metadata": {
        "id": "nseHscFfmoSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ Deployment"
      ],
      "metadata": {
        "id": "EwcYNj4AGbio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mb.deploy(classify_document_text)"
      ],
      "metadata": {
        "id": "hQzZ1RZDshde"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}